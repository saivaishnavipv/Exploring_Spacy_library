{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `Nlp` object\n",
    "\n",
    "At the center of Spacy is the object containing the processing pipeline. We usually call this variable `nlp`. For example to create an English `nlp` object you can import the English language class from `spacy.lang.en` and instanciated it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the English language class\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the nlp object\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `nlp` object like a function to analyze text. \n",
    "\n",
    "- It contains all the different components in the pipeline.\n",
    "- It also includes all language-specific rules used for tokenizing the text into words and punctuation.\n",
    "\n",
    "### The `Doc` object\n",
    "\n",
    "When you process a text with the `nlp` object, Spacy creates a `doc` object, \"doc\" from document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created by processing a string of text with the nlp object\n",
    "doc = nlp(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `doc` let you access information about the text in a structured way. No information is lost. The `doc` behaves like a normal Python sequence by the way. And lets you iterate over its tokens or get the tokens by its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "world\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "# Itereate over tokens in a Doc\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a token at a specific posiiton, you can index into the `doc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index into the Doc to get a single Token\n",
    "token = doc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Token object also provide various attributes that give you access more information about the tokens. For example the `.text` attribute returns the verbatin token text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world\n"
     ]
    }
   ],
   "source": [
    "# Get the token text via the .text attribute\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Span object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `span` object is a slide of the document consisting of one or more tokens. It is only a view of the document, it doesn't contain any data itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 'Span' object is a group of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To createa a span you can use Pyhton slice notation. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Hi this is vaishnavi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is vaishnavi\n"
     ]
    }
   ],
   "source": [
    "\n",
    "span = doc[1:6]\n",
    "\n",
    "# we can get Get the span text via the  \".text\" attribute\n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical attributes\n",
    "- .i  - gives the index number of token\n",
    "- .token - prints the text of every token in the doc\n",
    "- .is_punct,is_alpha,.like_num\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  [0, 1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I'am working at Data Labs since a year!\")\n",
    "print('Index: ', [token.i for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.text` returns the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  [\"I'am\", 'working', 'at', 'Data', 'Labs', 'since', 'a', 'year', '!']\n"
     ]
    }
   ],
   "source": [
    "print('Index: ', [token.text for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.is_alpha`, `.is_punct` and `.like_num` return boolean values indicating weather the token consists of alphanumeric characters, weather is punctuation or weather it simbolos a number. For example the token ten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  [False, True, True, True, True, True, True, True, False]\n",
      "Index:  [False, False, False, False, False, False, False, False, True]\n",
      "Index:  [False, False, False, False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "print('Index: ', [token.is_alpha for token in doc])\n",
    "print('Index: ', [token.is_punct for token in doc])\n",
    "print('Index: ', [token.like_num for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Support in spacy\n",
    "(https://spacy.io/usage/models#languages).\n",
    "it supports 30+ languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
