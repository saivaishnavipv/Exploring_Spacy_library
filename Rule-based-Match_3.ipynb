{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule-based Matching\n",
    "\n",
    "- Compared with regular expressions, the matcher works with doc objects  and tokens objects instead of only strings.\n",
    "- It is also more flexible, you can search for text but also other lexical attributes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match patterns\n",
    "\n",
    "Match patters are lists of dictionaries, each dictionary describes one token. The keys are the names of the token's attributes mapped to the expected values:\n",
    "\n",
    "### Match exact token texts:\n",
    "\n",
    "```python\n",
    "[{'ORTH': 'phone'}, {'ORTH': 'samsung'}]\n",
    "```\n",
    "In this example we are looking for two tokens with the texts `phone` and `samsung`.\n",
    "\n",
    "### Match lexical attributes:\n",
    "We can also match on other tokens attributes. Here we have two token whose lower case forms equal `iphone` and `x`:\n",
    "\n",
    "```python\n",
    "[{'LOWER': 'iphone'}, {'LOWER': 'x'}]\n",
    "```\n",
    "### Match any token attributes\n",
    "We can even write patters using attributes predicted by model. Here we are matching a token with the lemma `buy` plus a noun. \n",
    "```python\n",
    "[{'LEMMA': 'buy'}, {'POS': 'NOUN'}]\n",
    "```\n",
    "The lemma is the base form, so this patter would match prhases like \"buying milk\" or \"buy flowers\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Matcher \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Import the Matcher\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also load the model and create the nlp object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model and create the nlp object\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matcher is initialize with the shared vocabulary `nlp.vocab`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `matcher.add` method lets you add the pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the pattern to the matcher\n",
    "pattern = [{'ORTH': 'samsung'}, {'ORTH': 'phone'}]\n",
    "matcher.add('PHONE_PATTERN', None, pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first argument it is a unique id to identify which patter we would match. The second argument it is an optional call back. We don't need one here, so we set it to `None`. The third argument is the pattern. \n",
    "\n",
    "To match the patter on the text we can call the Matcher on any `Doc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process some text\n",
    "doc = nlp(\"New samsung phone release date out now\")\n",
    "\n",
    "# Call the matcher on the doc\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return the matches. When you call the Matcher on the doc it returns a list of tuples. It tubple consists on three values:\n",
    "\n",
    "- the `match_id`: hash value of the pattern name\n",
    "- the `start`: index of matched span\n",
    "- the `end`: index of the matched span\n",
    "\n",
    "This means that we can iterate over the matches and create a span object. Slice of the `Doc` at the start and end index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samsung phone\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the matches\n",
    "for match_id, start, end, in matches:\n",
    "    \n",
    "    # Get the matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching for lexical attributes\n",
    "\n",
    "Here it is an example of a more complex pattern using lexical attributes. We are looking for five tokens. A tokenn consisting on only digists, free case insesitive tokens for `fifa`, `word` and `cup` and a token which consists on punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [\n",
    "    {'IS_DIGIT': True},\n",
    "    {'LOWER': 'fifa'},\n",
    "    {'LOWER': 'world'},\n",
    "    {'LOWER': 'cup'},\n",
    "    {'IS_PUNCT': True}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"2018 FIFA World Cup: France won!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the pattern to the matcher\n",
    "matcher.add('FIFA_PATTERN', None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the matcher on the doc\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 FIFA World Cup:\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the matches\n",
    "for match_id, start, end, in matches:\n",
    "    \n",
    "    # Get the matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pattern matches the tokens `2018 FIFA World Cup:`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching other token attributes\n",
    "\n",
    "In this example, we are looking for two tokens. A verb with the lemma `love` followed by a noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [\n",
    "    {'LEMMA': 'love', 'POS': 'VERB'},\n",
    "    {'POS': 'NOUN'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I loved dogs but now I love cats more.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the pattern to the matcher\n",
    "matcher.add('LOVE', None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the matcher on the doc\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loved dogs\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the matches\n",
    "for match_id, start, end, in matches:\n",
    "    \n",
    "    # Get the matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This patter will match `loved dogs` and `love cats`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using operators and quantifiers (1)\n",
    "\n",
    "Operators and quantifiers let you define how often the token should be matched. They can be added using the `OP` key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [\n",
    "    {'LEMMA': 'buy'},\n",
    "    {'POS': 'DET', 'OP': '?'}, # optional: match 0 or 1 times\n",
    "    {'POS': 'NOUN'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the question mark operator makes the determinant token optional so, it will match a token with the lemma `buy` an optional article and a noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I bought a smartphone. Now I'm buying accessories for it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the pattern to the matcher\n",
    "matcher.add('BUY', None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the matcher on the doc\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bought a smartphone\n",
      "buying accessories\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the matches\n",
    "for match_id, start, end, in matches:\n",
    "    \n",
    "    # Get the matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using operators and quantifiers (2)\n",
    "\n",
    "`OP` can have one of four values:\n",
    "\n",
    "| op/quant| Description                       |\n",
    "|----------------------|-------------------------|\n",
    "| {'OP': !}|\tNegation: match 0 times      |\n",
    "| {'OP': ?}|\tOptional: match 0 or 1 times |\n",
    "| {'OP': +}|\tMatch 1 or more times |\n",
    "| {'OP': *}|\tMatch 0 or more times |\n",
    "\n",
    "- An exclamation mark neagates the token, so it match zero times.\n",
    "- The question mark makes the token optional and matches it zero or one times.\n",
    "- A plus matches the token one or more times.\n",
    "- An asterix matches zero or more times.\n",
    "\n",
    "Operators can make your patterns a lot more powerfull. But they can add also more complexity. So use them wiselly. \n",
    "\n",
    "Token-based matching opens up lots of new possibilities for information extraction. Let's see some examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Matcher\n",
    "\n",
    "Let's try spaCy's rule-based `Matcher`. You'll be using the example from the previous exercise and write a pattern that can match the phrase \"iPhone X\" in the text. The `nlp` object and a processed `doc` are already available.\n",
    "\n",
    "- Import the `Matcher` from `spacy.matcher`.\n",
    "- Initialize it with the `nlp` object's shared `vocab`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Initialize the Matcher with the shared vocabulary\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Process some text\n",
    "doc = nlp(\"New samsung phone release date leaked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a pattern that matches the `TEXT` values of two tokens: \"samsung\" and \"phone\".\n",
    "- Use the `matcher.add` method to add the pattern to the matcher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing match patterns\n",
    "In this exercise, you'll practice writing more complex match patterns using different token attributes and operators. A matcher is already initialized and available as the variable matcher.\n",
    "\n",
    "- Write **one** pattern that only matches mentions of the *full* iOS versions: \"iOS 7\", \"iOS 11\" and \"iOS 10\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 3\n",
      "Match found: iOS 7\n",
      "Match found: iOS 11\n",
      "Match found: iOS 10\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"After making the iOS update you won't notice a radical system-wide redesign: nothing like the aesthetic upheaval we got with iOS 7. Most of iOS 11's furniture remains the same as in iOS 10. But you will discover some tweaks once you delve a little deeper.\")\n",
    "\n",
    "# Write a pattern for full iOS versions\n",
    "pattern = [{'TEXT': 'iOS'}, {'IS_DIGIT': True}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add('IOS_VERSION_PATTERN', None, pattern)\n",
    "\n",
    "matches = matcher(doc)\n",
    "print('Total matches found:', len(matches))\n",
    "\n",
    "# Iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print('Match found:', doc[start:end].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write **one** pattern that only matches forms of \"download\" (tokens with the lemma \"download\"), followed by a proper noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 3\n",
      "Match found: downloaded Fortnite\n",
      "Match found: downloading Minecraft\n",
      "Match found: download Winzip\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"i downloaded Fortnite on my laptop and can't open the game at all. Help? so when I was downloading Minecraft, I got the Windows version where it is the '.zip' folder and I used the default program to unpack it... do I also need to download Winzip?\")\n",
    "\n",
    "# Write a pattern that matches a form of \"download\" plus proper noun\n",
    "pattern = [{'LEMMA': 'download'}, {'POS': 'PROPN'}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add('DOWNLOAD_THINGS_PATTERN', None, pattern)\n",
    "matches = matcher(doc)\n",
    "print('Total matches found:', len(matches))\n",
    "\n",
    "# Iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print('Match found:', doc[start:end].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write **one** pattern that matches adjectives followed by one or two nouns (one noun and one optional noun)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 4\n",
      "Match found: downloaded Fortnite\n",
      "Match found: my laptop\n",
      "Match found: downloading Minecraft\n",
      "Match found: download Winzip\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"i downloaded Fortnite on my laptop and can't open the game at all. Help? so when I was downloading Minecraft, I got the Windows version where it is the '.zip' folder and I used the default program to unpack it... do I also need to download Winzip?\")\n",
    "\n",
    "# Write a pattern that matches a form of \"download\" plus proper noun\n",
    "pattern = [{'POS': 'ADJ'}, {'POS': 'NOUN'}, {'OP': '?'}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add('DOWNLOAD_THINGS_PATTERN', None, pattern)\n",
    "matches = matcher(doc)\n",
    "print('Total matches found:', len(matches))\n",
    "\n",
    "# Iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print('Match found:', doc[start:end].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference:\n",
    "\n",
    "- [Rule-based matching examples on spaCy](https://spacy.io/usage/linguistic-features#section-rule-based-matching)\n",
    "\n",
    "- [Writing Your Own Resume Parser](https://www.omkarpathak.in/2018/12/18/writing-your-own-resume-parser/#sixth-step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
